# -*- coding: utf-8 -*-
"""fireproj_trainML_and_predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FDetDZl0lpm6mYPSrIFOnATHmIm97fYf
"""

# I have two datasets in my google drive.
#I have the combined_fire_weather_data_pastyr.csv file and the
#fire_weather_dates_ML_binary.csv file.
#I want to use the combined_fire_weather_data_pastyr.csv files columns of TEMP,
# past_day_fire_bin, WDSP,DEWP, and PRCP
#to train a logistic regression machine learning model to predict the
#fire_weather_dates_ML_binary.csv column Fire_exist .

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Load the datasets
df_weather = pd.read_csv('/content/drive/My Drive/combined_fire_weather_data_pastyr.csv')
df_fire = pd.read_csv('/content/drive/My Drive/fire_weather_dates_ML_binary.csv')

# Include DATE in df_weather for merging, but it's not a feature for training
columns_to_use = ['DATE', 'TEMP', 'past_day_fire_bin', 'WDSP', 'DEWP', 'PRCP']
df_weather = df_weather[columns_to_use]

# Convert 'DATE' columns to datetime
df_weather['DATE'] = pd.to_datetime(df_weather['DATE'])
df_fire['DATE'] = pd.to_datetime(df_fire['date'])
df_fire.drop('date', axis=1, inplace=True)  # Drop the original 'date' column to avoid duplication


# Remove duplicate dates, keeping the first occurrence
# Note that weather info doesn't change for multiple entries of the same DATE
# so this has no bearing on training the MODEL
# multiple dates are kept so that we can map the fire locations
df_weather_no_duplicates = df_weather.drop_duplicates(subset='DATE', keep='first')

# Merge the datasets on the 'DATE' column
combined_df = pd.merge(df_weather_no_duplicates, df_fire, on='DATE', how = 'inner')

# Define features (X) and target (y)
features = ['TEMP', 'past_day_fire_bin', 'WDSP', 'DEWP', 'PRCP']
X = combined_df[features]
y = combined_df['Fire_exist']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create logistic regression model
model = LogisticRegression()

# Train the model
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

#How can I use this model to predict the next date in the data (11/28/2023)?
# What I need is something that can be ran every morning that will check
# if can update any missing data from our combined dataset from the
# NOAA and MODIS data.
# Then it retrains the model
# Then it pulls the most recent hourly weather data, combines with a check
# of whether the most recent data point in our data has past_day_fire_bin = 1 or 0
# and then makes a prediction.

#I'm going to start with pulling the most recent hourly weather data, ...
# I need to convert Temp to fahrenheit and adjust the rest of the flags as well
# It looks like GSOD has different measurements
# year, hourly WDSP is in meters per second while GSOD WDSP is in .1 knots


import pandas as pd

# Define the URL of the CSV file
url = 'https://www.ncei.noaa.gov/data/global-hourly/access/2023/91190022516.csv'

# Read the CSV file from the URL
df = pd.read_csv(url, low_memory=False)

# Rename the columns as required
column_renames = {'WND': 'WDSP', 'DEW': 'DEWP', 'TMP': 'TEMP', 'AA1': 'PRCP'}
df.rename(columns=column_renames, inplace=True)

# Convert columns to string to safely perform string operations
df['WDSP'] = df['WDSP'].astype(str)
df['DEWP'] = df['DEWP'].astype(str)
df['TEMP'] = df['TEMP'].astype(str)
df['PRCP'] = df['PRCP'].astype(str)

# Function to check and filter based on '9999' value
def filter_9999(value):
    parts = value.split(',')
    if len(parts) > 1 and parts[1].startswith('9999'):
        return False
    return True

# Filter out rows based on '9999' value
df = df[df['WDSP'].apply(lambda x: filter_9999(x))]
df = df[df['DEWP'].apply(lambda x: filter_9999(x))]
df = df[df['TEMP'].apply(lambda x: filter_9999(x))]
df = df[df['PRCP'].apply(lambda x: filter_9999(x))]


# Convert the DATE column to datetime and truncate to just the date part
df['DATE'] = pd.to_datetime(df['DATE']).dt.date

# Extract the wind speed part from the 'WDSP' column
# Assuming the wind speed (in tenths of meters per second) is the fourth element after splitting
df['WDSP'] = df['WDSP'].str.split(',').str[3].str.extract(r'(\d+)').astype(float)

# # Convert WDSP from meters per second to knots
# 1 m/s = 1/0.51444 knots
df['WDSP'] = df['WDSP'] / 5.1444


# Convert columns to string to safely perform string operations
df['DEWP'] = df['DEWP'].astype(str)

# Extract the numeric part from the 'DEWP' column
df['DEWP'] = df['DEWP'].str.split(',').str[0].str.extract(r'(\d+)').astype(float) / 10

# Convert DEWP from Celsius to Fahrenheit
df['DEWP'] = (df['DEWP'] * 9/5) + 32


# Extract the numeric part from the 'TEMP' column without the sign
df['TEMP'] = df['TEMP'].str.split(',').str[0].str.extract(r'(\d+)')

# Convert TEMP from tenths of Celsius to Fahrenheit
df['TEMP'] = df['TEMP'].astype(float) / 10  # Convert to Celsius
df['TEMP'] = (df['TEMP'] * 9/5) + 32  # Convert to Fahrenheit

# Convert columns to string to safely perform string operations
df['PRCP'] = df['PRCP'].astype(str)

# Extract the numeric part from the 'PRCP' column
# Assuming the precipitation (in tenths of millimeters) is the second element after splitting
df['PRCP'] = df['PRCP'].str.split(',').str[1].str.extract(r'(\d+)').astype(float)

# Convert PRCP from tenths of millimeters to millimeters
df['PRCP'] = df['PRCP'] / 100

# Convert PRCP from millimeters to hundredths of inches
df['PRCP'] = df['PRCP'] * 0.0393701

# Select only the required columns
columns_to_select = ['DATE', 'WDSP', 'STATION', 'DEWP', 'PRCP', 'TEMP']
df = df[columns_to_select]

# Filter out rows where any of the required columns are NaN
df = df.dropna(subset=columns_to_select)

# Select the last observation where all the required columns are not NaN
last_valid_observation = df.iloc[-1:]

# Display the last valid observation
print(last_valid_observation)

#combines with a check
# of whether the most recent data point in our data has past_day_fire_bin = 1 or 0
import pandas as pd

# Assuming you have already executed the previous steps and have df ready

# Filter out rows where any of the required columns are NaN
df = df.dropna(subset=columns_to_select)

# Select the last observation where all the required columns are not NaN
# Use .copy() to explicitly make it a separate DataFrame
last_valid_observation = df.iloc[-1:].copy()

# Load the 'combined_fire_weather_data_pastyr.csv' data
pastyr_df = pd.read_csv('/content/drive/My Drive/combined_fire_weather_data_pastyr.csv')

# Ensure the 'DATE' column is in datetime format
pastyr_df['DATE'] = pd.to_datetime(pastyr_df['DATE'])

# Get the most recent date's 'past_day_fire_bin' value
most_recent_fire_bin = pastyr_df.loc[pastyr_df['DATE'].idxmax(), 'past_day_fire_bin']

# Add the 'past_day_fire_bin' column to the 'last_valid_observation' DataFrame
last_valid_observation['past_day_fire_bin'] = most_recent_fire_bin

# Display the combined data
print(last_valid_observation)

# and then makes a prediction.

required_features = ['TEMP', 'past_day_fire_bin', 'WDSP', 'DEWP', 'PRCP']

# Assuming 'last_valid_observation' already has these features, we proceed to make a prediction
prediction_input = last_valid_observation[required_features]

# Use the trained model to predict the probability
predicted_probabilities = model.predict_proba(prediction_input)

# The result will be in the form of an array of probabilities for each class ([probability of 0, probability of 1])
# For binary classification, the probability of class 1 can be taken as the confidence level
confidence_level = predicted_probabilities[0][1]

# Output the prediction and confidence level
predicted_fire_risk = model.predict(prediction_input)
print("Predicted Fire Risk for today:", predicted_fire_risk[0])
print("Confidence Level of the prediction:", confidence_level)


required_features = ['TEMP', 'past_day_fire_bin', 'WDSP', 'DEWP', 'PRCP']

# Assuming 'last_valid_observation' already has these features, we proceed to make a prediction
prediction_input = last_valid_observation[required_features]

# Use the trained model to predict the probability
predicted_probabilities = model.predict_proba(prediction_input)

# The result will be in the form of an array of probabilities for each class ([probability of 0, probability of 1])
# For binary classification, the probability of class 1 can be taken as the confidence level
confidence_level = predicted_probabilities[0][1]

# Output the prediction and confidence level
predicted_fire_risk = model.predict(prediction_input)[0]

# Create a DataFrame with date, predicted_fire_risk, and confidence level
prediction_df = pd.DataFrame({
    'date': last_valid_observation['DATE'],
    'predicted_fire_risk': predicted_fire_risk,
    'confidence_level': confidence_level
})

print(prediction_df)

#Now I need to output the map with todays FRP's and the prediction that is smaller or
# larger based on confidence level and is blue if no fire risk and orange if there is a
# fire risk

import folium
import pandas as pd
from geopy.distance import geodesic
import branca.colormap as cm


# Function to get fire data from FIRMS API for a specific date and parse out the data for just Maui
def get_fire_data(date):
    firm_api = f"https://firms.modaps.eosdis.nasa.gov//api/area/csv/33c0bb32b80831ae1cb4bb94211611c8/MODIS_NRT/world/1/{date}"
    df_firm = pd.read_csv(firm_api)
    df_firm = df_firm[['acq_date', 'latitude', 'longitude', 'frp']]
    df_firm = df_firm[(df_firm['latitude'] >= 20.500) & (df_firm['latitude'] <= 21.0000)]
    df_firm = df_firm[(df_firm['longitude'] >= -156.5000) & (df_firm['longitude'] <= -156.0000)]
    df_firm = df_firm[df_firm['frp'] > 0]
    df_firm = df_firm.sort_values(by='latitude')
    return df_firm

# Function to calculate square corners around a point
def get_square_corners(lat, lon, distance_km=0.5):
    # Calculate the four corners of a square centered at (lat, lon)
    # distance_km is the half-side of the square, defaulting to 0.5 km for a 1km x 1km square
    center = (lat, lon)
    north = geodesic(kilometers=distance_km).destination(center, bearing=0)
    east = geodesic(kilometers=distance_km).destination(center, bearing=90)
    south = geodesic(kilometers=distance_km).destination(center, bearing=180)
    west = geodesic(kilometers=distance_km).destination(center, bearing=270)

    ne = (north.latitude, east.longitude)
    se = (south.latitude, east.longitude)
    sw = (south.latitude, west.longitude)
    nw = (north.latitude, west.longitude)

    return [ne, se, sw, nw, ne]  # Return coordinates to form a closed square

# Function to determine circle size based on prediction score
def get_circle_radius(prediction_score, min_radius=1000, max_radius=8500):
    # Scale the prediction score (0 to 1) to the radius range (min_radius to max_radius)
    scaled_radius = prediction_score * (max_radius - min_radius) + min_radius

    # Ensure the radius does not go below the minimum or above the maximum
    return max(min(scaled_radius, max_radius), min_radius)



# Function to create a map with fire locations marked as squares
def create_fire_map(prediction_df):
    # Directly access the values in the single row of prediction_df
    date = prediction_df['date'].iloc[0]
    predicted_fire_risk = prediction_df['predicted_fire_risk'].iloc[0]
    confidence_level = prediction_df['confidence_level'].iloc[0]

    # Fetch fire data for the specific date
    df_fires = get_fire_data(date)
    maui_center = [20.7984, -156.3319]
    maui_map = folium.Map(location=maui_center, tiles='CartoDB dark_matter', zoom_start=10)

    # Check if there are fire spots
    if not df_fires.empty:
        # Create a red color scale for the FRP values
        max_frp = df_fires['frp'].max()
        min_frp = df_fires['frp'].min()

        # Define a color scale from light red to dark red using hexadecimal colors
        colormap = cm.LinearColormap(['#ffcccc', '#ff0000'], vmin=min_frp, vmax=max_frp)

        for _, row in df_fires.iterrows():
            corners = get_square_corners(row['latitude'], row['longitude'])
            color = colormap(row['frp'])
            folium.Polygon(
                locations=corners,
                color=color,
                fill=True,
                fill_color=color
            ).add_to(maui_map)

        # Add the color scale legend to the map
        colormap.caption = 'Fire Radiative Power (FRP)'
        maui_map.add_child(colormap)
    else:
        # Add a message to the map indicating no fire spots
        folium.Marker(
            location=[20.7984, -156.3319],
            popup="No fire locations on this date",
            icon=folium.Icon(color="blue", icon="info-sign")
        ).add_to(maui_map)

    # Plot the prediction as a circle
    circle_color = 'orange' if predicted_fire_risk > 0 else 'blue'
    circle_radius = get_circle_radius(confidence_level)
    folium.Circle(
        location=maui_center,  # Adjust location if necessary
        radius=circle_radius,
        color=circle_color,
        fill=True,
        fill_color=circle_color
    ).add_to(maui_map)

    # Save map for each date
    maui_map.save(f'maui_fire_map_with_predictions_{date}.html')

    return maui_map



# Example usage
fire_map = create_fire_map(prediction_df)
fire_map.save('maui_fire_map_with_predictions.html')

fire_map